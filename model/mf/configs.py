configs = {
    'embedding_size': 256,
    'learning_rate': 0.01,
    'training_epochs': 10,
    'self.batch_size': 256,
    'emb_init_value': 1,
    'lambda_value': 0.0001,
    'display_step': 100,
    'optimize_method': 'adam',
    'model_name': "mf_model"
}